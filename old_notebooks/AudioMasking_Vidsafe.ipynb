{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOVDIVurgGJbrnqLi2+R6Ah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aparnamol-KS/VidSafe/blob/Aparna/AudioMasking_Vidsafe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pipeline"
      ],
      "metadata": {
        "id": "572aYcIPRKSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faster-whisper\n",
        "!pip install transformers\n",
        "!pip install ffmpeg-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJg7pj28RJSt",
        "outputId": "6ae95355-c97c-426d-9734-83a65adda7d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.36.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.22.1)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (1.23.2)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (16.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (2.0.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (1.2.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.12/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -y install ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2gnT7fcRmkb",
        "outputId": "3571b3db-e94f-4ff9-b28e-969465532d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OyZ4Pz31Rv6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracting Audio from video"
      ],
      "metadata": {
        "id": "lKBpwCOM5Y1i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hPQyiRr-5gF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Load your video file\n",
        "video = VideoFileClip(\"/content/1000088539.mp4\")\n",
        "\n",
        "# Extract audio\n",
        "audio = video.audio\n",
        "\n",
        "# Export audio as MP3\n",
        "audio.write_audiofile(\"/content/extracted_audio.mp3\", codec='mp3')\n",
        "\n",
        "print(\"Audio extracted successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "aEsLsRYpFAGz",
        "outputId": "8de15f17-4ed9-4e51-b93b-ebaaa9831c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  match = re.search('\\d+$', rotation_line)\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in /content/extracted_audio.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "chunk:   0%|          | 0/1178 [00:00<?, ?it/s, now=None]\u001b[A\n",
            "chunk:  10%|▉         | 113/1178 [00:00<00:01, 553.92it/s, now=None]\u001b[A\n",
            "chunk:  15%|█▍        | 176/1178 [00:00<00:01, 584.53it/s, now=None]\u001b[A\n",
            "chunk:  22%|██▏       | 259/1178 [00:00<00:01, 673.74it/s, now=None]\u001b[A\n",
            "chunk:  30%|███       | 356/1178 [00:00<00:01, 769.25it/s, now=None]\u001b[A\n",
            "chunk:  37%|███▋      | 436/1178 [00:00<00:00, 769.63it/s, now=None]\u001b[A\n",
            "chunk:  44%|████▍     | 521/1178 [00:00<00:00, 787.41it/s, now=None]\u001b[A\n",
            "chunk:  52%|█████▏    | 616/1178 [00:00<00:00, 837.68it/s, now=None]\u001b[A\n",
            "chunk:  60%|█████▉    | 704/1178 [00:00<00:00, 849.74it/s, now=None]\u001b[A\n",
            "chunk:  68%|██████▊   | 799/1178 [00:01<00:00, 879.46it/s, now=None]\u001b[A\n",
            "chunk:  75%|███████▌  | 888/1178 [00:01<00:00, 867.45it/s, now=None]\u001b[A\n",
            "chunk:  83%|████████▎ | 980/1178 [00:01<00:00, 882.52it/s, now=None]\u001b[A\n",
            "chunk:  91%|█████████ | 1069/1178 [00:01<00:00, 872.08it/s, now=None]\u001b[A\n",
            "chunk:  98%|█████████▊| 1157/1178 [00:01<00:00, 868.97it/s, now=None]\u001b[A\n",
            "                                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Audio extracted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Audio Generation"
      ],
      "metadata": {
        "id": "2-glb9sCTEbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8i3ptz1TIn6",
        "outputId": "e5ba9f10-cfcb-4507-dde2-ca16c1c6104b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.12/dist-packages (2.5.4)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from gTTS) (2.32.4)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.12/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "\n",
        "# Combine all sentences into a single passage\n",
        "offensive_sentences = [\n",
        "    \"How are you doing today?\",\n",
        "    \"This is a friendly conversation.\",\n",
        "    \"You are such an idiot.\",\n",
        "    \"Shut the hell up.\",\n",
        "    \"The weather today is sunny and beautiful.\",\n",
        "    \"I am looking forward to our trip next week.\",\n",
        "    \"She bought a new book from the store.\",\n",
        "    \"Thank you for helping me with the task.\",\n",
        "    \"What the hell are you doing?\",\n",
        "    \"This is a stupid idea.\",\n",
        "    \"You piece of crap.\",\n",
        "    \"This is a friendly conversation.\",\n",
        "    \"Don't be a jerk.\",\n",
        "    \"Can you help me with my homework?\",\n",
        "    \"This project is coming along very nicely.\",\n",
        "    \"Please remember to submit your assignment on time.\",\n",
        "\n",
        "    \"Stop talking nonsense you fool.\",\n",
        "    \"You are acting like an asshole.\",\n",
        "    \"Mind your damn business.\",\n",
        "     \"Hello, how are you doing today?\",\n",
        "    \"Let's meet tomorrow at the cafe.\",\n",
        "    \"I really enjoyed the movie last night.\",\n",
        "    \"Let's meet tomorrow morning.\",\n",
        "    \"This is freaking stupid.\"\n",
        "]\n",
        "\n",
        "# Join them into a single string, adding optional pauses using punctuation\n",
        "passage = \" \".join(offensive_sentences)\n",
        "\n",
        "# Generate audio\n",
        "tts = gTTS(text=passage, lang='en')\n",
        "tts.save(\"offensive_combined.mp3\")\n",
        "\n",
        "print(\"Combined offensive audio saved as offensive_combined.mp3\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3Vrc5xLTLJp",
        "outputId": "a6e2524e-a442-4d76-ce4f-6ba4f23f3033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined offensive audio saved as offensive_combined.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kdPs7zwBVd-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Whisper model"
      ],
      "metadata": {
        "id": "Gfyku2XDYc69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faster-whisper\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OJi7plqYfyh",
        "outputId": "005dbcbe-9df5-401c-fb45-77ca24145182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.36.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.22.1)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (1.23.2)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (16.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (2.0.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (1.2.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from faster_whisper import WhisperModel\n",
        "\n",
        "audio_file = \"offensive_combined.mp3\"\n",
        "\n",
        "# Load smaller, faster model\n",
        "model = WhisperModel(\"small\", device=\"cuda\", compute_type=\"float16\")\n",
        "\n",
        "# Transcribe audio with word-level timestamps\n",
        "segments, info = model.transcribe(audio_file, word_timestamps=True)\n",
        "\n",
        "# Store sentences along with their corresponding words\n",
        "sentence_segments = []\n",
        "\n",
        "for seg in segments:\n",
        "    sentence_data = {\n",
        "        \"text\": seg.text.strip(),\n",
        "        \"start\": seg.start,\n",
        "        \"end\": seg.end,\n",
        "        \"words\": []\n",
        "    }\n",
        "\n",
        "    for w in seg.words:\n",
        "        sentence_data[\"words\"].append({\n",
        "            \"word\": w.word,\n",
        "            \"start\": w.start,\n",
        "            \"end\": w.end\n",
        "        })\n",
        "\n",
        "    sentence_segments.append(sentence_data)\n",
        "\n",
        "# Example output\n",
        "print(\"Example sentence segment:\", sentence_segments[0])\n",
        "print(\"Words in this sentence:\", sentence_segments[0][\"words\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huZ8L_5mYgqn",
        "outputId": "6981f364-9a6b-4aa1-ddda-a4b788f81034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example sentence segment: {'text': 'How are you doing today? This is a friendly conversation.', 'start': np.float64(0.0), 'end': np.float64(3.7), 'words': [{'word': ' How', 'start': np.float64(0.0), 'end': np.float64(0.28)}, {'word': ' are', 'start': np.float64(0.28), 'end': np.float64(0.38)}, {'word': ' you', 'start': np.float64(0.38), 'end': np.float64(0.52)}, {'word': ' doing', 'start': np.float64(0.52), 'end': np.float64(0.84)}, {'word': ' today?', 'start': np.float64(0.84), 'end': np.float64(1.24)}, {'word': ' This', 'start': np.float64(1.94), 'end': np.float64(2.18)}, {'word': ' is', 'start': np.float64(2.18), 'end': np.float64(2.36)}, {'word': ' a', 'start': np.float64(2.36), 'end': np.float64(2.5)}, {'word': ' friendly', 'start': np.float64(2.5), 'end': np.float64(2.78)}, {'word': ' conversation.', 'start': np.float64(2.78), 'end': np.float64(3.7)}]}\n",
            "Words in this sentence: [{'word': ' How', 'start': np.float64(0.0), 'end': np.float64(0.28)}, {'word': ' are', 'start': np.float64(0.28), 'end': np.float64(0.38)}, {'word': ' you', 'start': np.float64(0.38), 'end': np.float64(0.52)}, {'word': ' doing', 'start': np.float64(0.52), 'end': np.float64(0.84)}, {'word': ' today?', 'start': np.float64(0.84), 'end': np.float64(1.24)}, {'word': ' This', 'start': np.float64(1.94), 'end': np.float64(2.18)}, {'word': ' is', 'start': np.float64(2.18), 'end': np.float64(2.36)}, {'word': ' a', 'start': np.float64(2.36), 'end': np.float64(2.5)}, {'word': ' friendly', 'start': np.float64(2.5), 'end': np.float64(2.78)}, {'word': ' conversation.', 'start': np.float64(2.78), 'end': np.float64(3.7)}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cB7c5MPbYjcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TE7Ww7cpfyzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Detecting Toxicity\n"
      ],
      "metadata": {
        "id": "cx2bbvC4fz0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install detoxify\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7j1-oDBLf5iz",
        "outputId": "aad04a4b-3ad5-4243-c53d-cf0a6568dbb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: detoxify in /usr/local/lib/python3.12/dist-packages (0.5.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from detoxify) (4.57.2)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from detoxify) (2.9.0+cu126)\n",
            "Requirement already satisfied: sentencepiece>=0.1.94 in /usr/local/lib/python3.12/dist-packages (from detoxify) (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers->detoxify) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->detoxify) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.0->detoxify) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.0->detoxify) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->detoxify) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->detoxify) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->detoxify) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->detoxify) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Sentence level profanity detection"
      ],
      "metadata": {
        "id": "UJisejA3pih3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detoxify import Detoxify\n",
        "\n",
        "# Load Detoxify model\n",
        "detox_model = Detoxify('original')  # you can also use 'multilingual'\n",
        "\n",
        "# Threshold for classifying toxicity\n",
        "THRESHOLD = 0.5\n",
        "\n",
        "# Detect toxic sentences and store the score inside sentence_segments\n",
        "for seg in sentence_segments:  # sentence_segments contains text + words\n",
        "    result = detox_model.predict(seg[\"text\"])\n",
        "    score = float(result[\"toxicity\"])  # probability of being toxic\n",
        "    seg[\"toxicity\"] = score\n",
        "    seg[\"is_toxic\"] = score > THRESHOLD\n",
        "\n",
        "# Extract only toxic sentences if needed\n",
        "toxic_sentences = [seg for seg in sentence_segments if seg[\"is_toxic\"]]\n",
        "\n",
        "# Example output\n",
        "print(\"Example toxic sentence:\", toxic_sentences[0] if toxic_sentences else \"None\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrSbbQFxf3bu",
        "outputId": "c8da2984-fbe0-4700-ce22-09654c6c2b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example toxic sentence: {'text': 'You are such an idiot. Shut the hell up. The weather today is sunny and beautiful.', 'start': np.float64(4.32), 'end': np.float64(9.4), 'words': [{'word': ' You', 'start': np.float64(4.32), 'end': np.float64(4.56)}, {'word': ' are', 'start': np.float64(4.56), 'end': np.float64(4.68)}, {'word': ' such', 'start': np.float64(4.68), 'end': np.float64(4.94)}, {'word': ' an', 'start': np.float64(4.94), 'end': np.float64(5.14)}, {'word': ' idiot.', 'start': np.float64(5.14), 'end': np.float64(5.4)}, {'word': ' Shut', 'start': np.float64(6.1), 'end': np.float64(6.26)}, {'word': ' the', 'start': np.float64(6.26), 'end': np.float64(6.44)}, {'word': ' hell', 'start': np.float64(6.44), 'end': np.float64(6.66)}, {'word': ' up.', 'start': np.float64(6.66), 'end': np.float64(6.98)}, {'word': ' The', 'start': np.float64(7.28), 'end': np.float64(7.42)}, {'word': ' weather', 'start': np.float64(7.42), 'end': np.float64(7.7)}, {'word': ' today', 'start': np.float64(7.7), 'end': np.float64(8.06)}, {'word': ' is', 'start': np.float64(8.06), 'end': np.float64(8.34)}, {'word': ' sunny', 'start': np.float64(8.34), 'end': np.float64(8.66)}, {'word': ' and', 'start': np.float64(8.66), 'end': np.float64(8.9)}, {'word': ' beautiful.', 'start': np.float64(8.9), 'end': np.float64(9.4)}], 'toxicity': 0.9895396828651428, 'is_toxic': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yux8A0KPliJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-1HwqgLwliLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eEKSdXOEliOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Word level profanity detection"
      ],
      "metadata": {
        "id": "zSMCeGI4pqc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import string\n",
        "\n",
        "# --------------------------\n",
        "# 1️⃣ Load Roberta Toxicity Model\n",
        "# --------------------------\n",
        "model_name = \"s-nlp/roberta_toxicity_classifier\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "THRESHOLD = 0.5  # Adjust for word-level detection (lower if you want more sensitivity)\n",
        "\n",
        "# --------------------------\n",
        "# 2️⃣ Helper function to get toxicity score\n",
        "# --------------------------\n",
        "def toxic_score(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "        probs = torch.softmax(logits, dim=1)[0]\n",
        "        return float(probs[1])  # probability of toxic class\n",
        "\n",
        "# --------------------------\n",
        "# 3️⃣ Word-level toxicity detection\n",
        "# --------------------------\n",
        "def get_word_level_toxicity(toxic_sentences, threshold=THRESHOLD):\n",
        "    masked_segments = []  # List of (start_time, end_time, word, score)\n",
        "\n",
        "    for seg in toxic_sentences:\n",
        "        words = seg[\"words\"]\n",
        "        for w in words:\n",
        "            word_text = w[\"word\"].strip().lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "            if not word_text:\n",
        "                continue\n",
        "            score = toxic_score(word_text)\n",
        "            if score >= threshold:\n",
        "                masked_segments.append({\n",
        "                    \"start\": float(w[\"start\"]),\n",
        "                    \"end\": float(w[\"end\"]),\n",
        "                    \"word\": w[\"word\"].strip(),\n",
        "                    \"score\": score\n",
        "                })\n",
        "\n",
        "    return masked_segments\n",
        "\n",
        "# --------------------------\n",
        "# 4️⃣ Run word-level detection\n",
        "# --------------------------\n",
        "word_level_toxic = get_word_level_toxicity(toxic_sentences)\n",
        "\n",
        "# --------------------------\n",
        "# 5️⃣ Show results\n",
        "# --------------------------\n",
        "print(\"Word-level toxic segments:\")\n",
        "for seg in word_level_toxic:\n",
        "    print(f\"{seg['start']:.2f} → {seg['end']:.2f}  [{seg['word']}]  score: {seg['score']:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owX76duN9hfB",
        "outputId": "81a3a573-d147-4cf2-f9f9-9c696643c6e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at s-nlp/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word-level toxic segments:\n",
            "5.14 → 5.40  [idiot.]  score: 1.000\n",
            "20.30 → 20.62  [stupid]  score: 0.999\n",
            "22.46 → 22.80  [crap.]  score: 0.999\n",
            "37.32 → 37.68  [fool.]  score: 0.998\n",
            "39.36 → 39.68  [asshole.]  score: 0.997\n",
            "40.90 → 41.18  [damn]  score: 0.998\n",
            "52.62 → 53.12  [stupid.]  score: 0.999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5VlJ3_ZOf_bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beep Voice\n"
      ],
      "metadata": {
        "id": "6dTXg7hIEHuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.generators import Sine\n",
        "\n",
        "# Load your MP3 audio\n",
        "audio = AudioSegment.from_file(\"/content/offensive_combined.mp3\", format=\"mp3\")\n",
        "\n",
        "# Apply mute/beep for each toxic word\n",
        "for seg in word_level_toxic:\n",
        "    start_ms = int(seg['start'] * 1000)  # convert to milliseconds\n",
        "    end_ms = int(seg['end'] * 1000)\n",
        "\n",
        "    # Option 1: Silence\n",
        "    # audio = audio[:start_ms] + AudioSegment.silent(duration=(end_ms-start_ms)) + audio[end_ms:]\n",
        "\n",
        "    # Option 2: Beep instead of silence\n",
        "    beep = Sine(1000).to_audio_segment(duration=(end_ms-start_ms))\n",
        "    audio = audio[:start_ms] + beep + audio[end_ms:]\n",
        "\n",
        "# Save the modified audio\n",
        "audio.export(\"censored_audio.mp3\", format=\"mp3\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3IfmfejELXz",
        "outputId": "dd0dcc02-d213-436d-b4d8-7b29a578ee30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='censored_audio.mp3'>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gajfi6cqLew7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}