from pathlib import Path
import json

from audio_processing.main import run_audio_moderation
from violence_detection.vision_pipeline import run_vision_pipeline
from audio_processing.merger import merge_audio_to_video
from Reporting.rag_vector import run_policy_rag


class VidSafePipeline:
    def __init__(
        self,
        output_dir: Path,
    ):
        self.output_dir = output_dir
        self.output_dir.mkdir(exist_ok=True)

        self.audio_dir = self.output_dir / "audio"
        self.audio_dir.mkdir(exist_ok=True)

        self.blurred_video = self.output_dir / "blurred_video.mp4"
        self.final_video = self.output_dir / "final_blurred_masked_video.mp4"

        self.evidence_file = self.output_dir / "moderation_evidence.json"
        self.policy_output = self.output_dir / "policy_violations_output.json"

    def run(self, input_video: Path):
        """
        Executes the full multimodal moderation pipeline.
        """
        input_video = input_video.resolve()

        # -----------------------------
        # 1. AUDIO MODERATION
        # -----------------------------
        audio_results = run_audio_moderation(
            input_video=str(input_video),
            work_dir=str(self.audio_dir)
        )

        # -----------------------------
        # 2. VISION PIPELINE
        # -----------------------------
        violence_results = run_vision_pipeline(
            input_video=str(input_video),
            output_video=str(self.blurred_video)
        )

        # SAFETY CHECK
        if not self.blurred_video.exists():
            raise RuntimeError("Blurred video was not generated by vision pipeline.")

        # -----------------------------
        # 3. MERGE AUDIO + VIDEO
        # -----------------------------
        merge_audio_to_video(
            original_video=str(self.blurred_video),
            new_audio=str(audio_results["censored_audio"]),
            out_video=str(self.final_video)
        )

        if not self.final_video.exists():
            raise RuntimeError("Final video was not generated.")

        # -----------------------------
        # 4. BUILD EVIDENCE
        # -----------------------------
        evidence = {
            "video_id": input_video.stem,
            "audio_moderation": audio_results,
            "violent_segments": violence_results.get("segments", []),
            "rtdetr_detections": violence_results.get("detections", [])
        }

        with open(self.evidence_file, "w") as f:
            json.dump(evidence, f, indent=2)

        # -----------------------------
        # 5. POLICY-AWARE RAG
        # -----------------------------
        run_policy_rag(
            evidence_file=str(self.evidence_file),
            output_file=str(self.policy_output)
        )

        return {
            "final_video": self.final_video,
            "policy_report": self.policy_output,
            "evidence": self.evidence_file
        }
